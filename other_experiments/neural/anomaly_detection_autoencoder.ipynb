{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Autoencoder for anomaly detection"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","## Libraries import"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:45.885277Z","iopub.status.busy":"2023-07-02T12:21:45.884942Z","iopub.status.idle":"2023-07-02T12:21:45.895538Z","shell.execute_reply":"2023-07-02T12:21:45.894434Z","shell.execute_reply.started":"2023-07-02T12:21:45.885250Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import os\n","import pandas as pd\n","from tqdm.notebook import tqdm \n","from typing import Callable, Dict, List, Set, Tuple\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import seaborn\n","import random\n","import category_encoders as ce\n","import sklearn.preprocessing\n","tfk = tf.keras\n","tfkl = tfk.layers\n","from sklearn.metrics import classification_report\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:47.252007Z","iopub.status.busy":"2023-07-02T12:21:47.251516Z","iopub.status.idle":"2023-07-02T12:21:47.259251Z","shell.execute_reply":"2023-07-02T12:21:47.258041Z","shell.execute_reply.started":"2023-07-02T12:21:47.251959Z"},"trusted":true},"outputs":[],"source":["from utils.preprocessing import labelEncodeCats, remove_categories_not_in_both, remove_outliers, CATEGORICAL_TO_DROP, NUMERICAL_NON_COUNTERS, NUMERICAL_TO_DROP\n","from utils.preprocessing import (\n","    encode_counters,\n","    remove_categories_not_in_both,\n","    remove_outliers,\n","    trigonometric_date_encoding,\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Random seed for reproducibility"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:47.263847Z","iopub.status.busy":"2023-07-02T12:21:47.263517Z","iopub.status.idle":"2023-07-02T12:21:47.284636Z","shell.execute_reply":"2023-07-02T12:21:47.283529Z","shell.execute_reply.started":"2023-07-02T12:21:47.263820Z"},"trusted":true},"outputs":[],"source":["seed = 1234\n","\n","np.random.seed(seed)\n","random.seed(seed)\n","tf.random.set_seed(seed)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset loading and preprocessing"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:47.302810Z","iopub.status.busy":"2023-07-02T12:21:47.302462Z","iopub.status.idle":"2023-07-02T12:21:47.319197Z","shell.execute_reply":"2023-07-02T12:21:47.317920Z","shell.execute_reply.started":"2023-07-02T12:21:47.302781Z"},"trusted":true},"outputs":[],"source":["TRAIN_VAL_DATA_PATH: Path = os.path.join('.', 'train_val_Enc_Counters.parquet')\n","TEST_DATA_PATH: Path = os.path.join('.', 'test_val_Enc_Counters.parquet')"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:47.321675Z","iopub.status.busy":"2023-07-02T12:21:47.320792Z","iopub.status.idle":"2023-07-02T12:21:52.187699Z","shell.execute_reply":"2023-07-02T12:21:52.186473Z","shell.execute_reply.started":"2023-07-02T12:21:47.321636Z"},"trusted":true},"outputs":[],"source":["df: pd.DataFrame = pd.read_parquet(TRAIN_VAL_DATA_PATH) \n","df = df.astype({f\"f_{i}\": \"category\" for i in range(2, 33)})\n","\n","test: pd.DataFrame = pd.read_parquet(TEST_DATA_PATH) \n","test = test.astype({f\"f_{i}\": \"category\" for i in range(2, 33)})\n","\n","df = df.astype({'f_1': 'int'})\n","test = test.astype({'f_1': 'int'})\n","\n","df = df.astype({'is_clicked': 'int'})\n","df = df.astype({'is_installed': 'int'})\n","\n","booleans = list(df.select_dtypes(['boolean']).columns)\n","for i in booleans:\n","    df[i] = df[i].astype('bool')\n","    test[i] = test[i].astype('bool')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Preprocessing"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:52.189790Z","iopub.status.busy":"2023-07-02T12:21:52.189289Z","iopub.status.idle":"2023-07-02T12:21:52.218630Z","shell.execute_reply":"2023-07-02T12:21:52.217288Z","shell.execute_reply.started":"2023-07-02T12:21:52.189761Z"},"trusted":true},"outputs":[],"source":["from utils.notebook_utils import collapse_binary\n","\n","# if do you want to collapse the binary columns set collapse_binary to True\n","activate_collapse_binary = False\n","\n","if activate_collapse_binary:\n","    categorical_columns: List[str] = [f\"f_{i}\" for i in range(2, 32 + 1)] + [\"f_394041\", \"f_33457\"]\n","else:\n","    categorical_columns: List[str] = [f\"f_{i}\" for i in range(2, 32 + 1)]\n","\n","numerical_columns: List[str] = [f\"f_{i}\" for i in range(42, 79 + 1)]\n","categorical_columns = [col for col in categorical_columns if col not in CATEGORICAL_TO_DROP]\n","numerical_columns = [\n","    col\n","    for col in numerical_columns\n","    if col not in NUMERICAL_TO_DROP and col in NUMERICAL_NON_COUNTERS\n","]\n","counter_columns: List[str] = [f\"f_{i}\" for i in range(42, 79 + 1)]\n","counter_columns = [\n","    col\n","    for col in counter_columns\n","    if col not in NUMERICAL_TO_DROP and col not in NUMERICAL_NON_COUNTERS\n","]\n","\n","def preprocess_data_nn(\n","    df_train: pd.DataFrame, df_val: pd.DataFrame, Y_train: pd.DataFrame, Y_val: pd.DataFrame\n",") -> Tuple[pd.DataFrame, pd.DataFrame]:\n","    \n","    categorical_columns: List[str] = [f\"f_{i}\" for i in range(2, 32 + 1)]\n","    numerical_columns: List[str] = [f\"f_{i}\" for i in range(42, 79 + 1)]\n","    boolean_columns: List[str] = [f\"f_{i}\" for i in range(33, 42)]\n","    categorical_columns = [col for col in categorical_columns if col not in CATEGORICAL_TO_DROP]\n","    numerical_columns = [col for col in numerical_columns if col not in NUMERICAL_TO_DROP and col in NUMERICAL_NON_COUNTERS]\n","    counter_columns: List[str] = [f\"f_{i}\" for i in range(42, 79 + 1)]\n","    counter_columns = [col for col in counter_columns if col not in NUMERICAL_TO_DROP and col not in NUMERICAL_NON_COUNTERS]\n","    \n","    print(\"Drop bad columns...\")\n","    df_train = df_train.drop(columns=CATEGORICAL_TO_DROP + NUMERICAL_TO_DROP)\n","    df_val = df_val.drop(columns=CATEGORICAL_TO_DROP + NUMERICAL_TO_DROP)\n","\n","    print(\"Collapsing binary columns...\")\n","    df_train = collapse_binary(df_train, dropOriginal=True)\n","    df_val = collapse_binary(df_val, dropOriginal=True)\n","\n","    print(\"Removes categories not in both...\")\n","    df_train, df_val = remove_categories_not_in_both(df_train, df_val, categorical_columns)\n","    \n","    cb_encoder = ce.CatBoostEncoder()\n","    cb_encoder.fit(df_train[categorical_columns], Y_train)\n","    df_train[categorical_columns] = cb_encoder.transform(df_train[categorical_columns])\n","    df_val[categorical_columns] = cb_encoder.transform(df_val[categorical_columns])\n","\n","    print(\"Normalizing counter columns...\")\n","    df_train, mins_train, steps_train = encode_counters(\n","        df=df_train,\n","        columns=counter_columns,\n","        mins=None,\n","        steps=None,\n","    )\n","    df_val, _, _ = encode_counters(\n","        df=df_val,\n","        columns=counter_columns,\n","        mins=mins_train,\n","        steps=steps_train,\n","    )\n","    counter_modes: pd.Series = df_train[counter_columns].mode()\n","    df_train = df_train.fillna(counter_modes)\n","    df_val = df_val.fillna(counter_modes)\n","    for col in counter_columns:\n","        n_zeros: int = (df_train[col] == 0).sum()\n","        if n_zeros > df_train.shape[0] * 0.95:\n","            df_train[col] = np.where(df_train[col].values, 1, 0)\n","            df_train = df_train.astype({col: \"bool\"})\n","            boolean_columns.append(col)\n","            df_val[col] = np.where(df_val[col].values, 1, 0)\n","            df_val = df_val.astype({col: \"bool\"})\n","        else:\n","            df_train[col] = np.log(df_train[col] + 0.5)\n","            df_val[col] = np.log(df_val[col] + 0.5)\n","\n","    print(\"Removing outliers from numerical columns...\")\n","    means: pd.Series = df_train[numerical_columns].mean()\n","    stds: pd.Series = df_train[numerical_columns].std()\n","    df_train = remove_outliers(\n","        df=df_train,\n","        columns=numerical_columns,\n","        coefficient=4,\n","        means=means,\n","        stds=stds,\n","    )\n","    df_val = remove_outliers(\n","        df=df_val,\n","        columns=numerical_columns,\n","        coefficient=4,\n","        means=means,\n","        stds=stds,\n","    )\n","\n","    print(\"Standardizing numerical columns...\")\n","    means_no_outliers: pd.Series = df_train[numerical_columns].mean()\n","    stds_no_outliers: pd.Series = df_train[numerical_columns].std()\n","    df_train.loc[:, numerical_columns] = (\n","        df_train.loc[:, numerical_columns] - means_no_outliers\n","    ) / stds_no_outliers\n","    df_val.loc[:, numerical_columns] = (\n","        df_val.loc[:, numerical_columns] - means_no_outliers\n","    ) / stds_no_outliers\n","    df_train = df_train.fillna(means_no_outliers)\n","    df_val = df_val.fillna(means_no_outliers)\n","\n","    scaler = MinMaxScaler()\n","    df_train = scaler.fit_transform(df_train)\n","    df_val = scaler.transform(df_val)\n","    \n","    return df_train, df_val"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Splitting and applying preprocessing"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:21:52.221223Z","iopub.status.busy":"2023-07-02T12:21:52.220407Z","iopub.status.idle":"2023-07-02T12:22:48.769397Z","shell.execute_reply":"2023-07-02T12:22:48.767919Z","shell.execute_reply.started":"2023-07-02T12:21:52.221191Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Drop bad columns...\n","Collapsing binary columns...\n","Removes categories not in both...\n","Normalizing counter columns...\n","Removing outliers from numerical columns...\n","Standardizing numerical columns...\n"]}],"source":["val_day = 65\n","train_df = df[(df[\"f_1\"] < val_day)]\n","val_df = df[df[\"f_1\"] >= val_day]\n","\n","X_train = train_df.drop(columns=[\"is_clicked\", \"is_installed\"])\n","y_train = train_df[[\"is_installed\"]]\n","X_val = val_df.drop(columns=[\"is_clicked\", \"is_installed\"])\n","y_val = val_df[[\"is_installed\"]]\n","\n","X_train, X_val = preprocess_data_nn(X_train, X_val, y_train, y_val)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:22:48.772139Z","iopub.status.busy":"2023-07-02T12:22:48.771693Z","iopub.status.idle":"2023-07-02T12:22:48.782093Z","shell.execute_reply":"2023-07-02T12:22:48.781000Z","shell.execute_reply.started":"2023-07-02T12:22:48.772091Z"},"trusted":true},"outputs":[],"source":["def build_model():\n","    # Define the autoencoder architecture\n","    n_features = X_train.shape[1]\n","\n","    input_layer = tfkl.Input(shape=(n_features,))\n","    x = tfkl.Dense(32, activation='relu', kernel_regularizer=tfk.regularizers.l2(1.1852537578175572e-05))(input_layer)\n","    x = tfkl.Dense(24, activation='relu', kernel_regularizer=tfk.regularizers.l2(1.1852537578175572e-05))(x)\n","\n","    x = tfkl.Dense(16, activation='relu', kernel_regularizer=tfk.regularizers.l2(1.1852537578175572e-05))(x)\n","\n","    x = tfkl.Dense(24, activation='relu', kernel_regularizer=tfk.regularizers.l2(1.1852537578175572e-05))(x)\n","    x = tfkl.Dense(32, activation='relu', kernel_regularizer=tfk.regularizers.l2(1.1852537578175572e-05))(x)\n","    output_layer = tfkl.Dense(n_features, activation=\"sigmoid\")(x)\n","\n","    autoencoder = tfk.models.Model(inputs=input_layer, outputs=output_layer)\n","    optimizer = tfk.optimizers.Adam(learning_rate=0.0010917112049605858)\n","    autoencoder.compile(optimizer=optimizer, loss=\"cosine_similarity\")\n","        \n","    return autoencoder"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:22:48.783602Z","iopub.status.busy":"2023-07-02T12:22:48.783261Z","iopub.status.idle":"2023-07-02T12:24:40.427737Z","shell.execute_reply":"2023-07-02T12:24:40.426687Z","shell.execute_reply.started":"2023-07-02T12:22:48.783573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["50639/50639 [==============================] - 108s 2ms/step - loss: -0.9738 - val_loss: -0.9721\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7e65ca511000>"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["autoencoder = build_model()\n","autoencoder.fit(X_train, \n","                X_train, \n","                epochs=1, \n","                batch_size=64,\n","                validation_data=(X_val, X_val),\n","                shuffle=True\n","                ) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Testing the experiment\n","We start by computing the similarity/distance over training's normal samples and we compare it with the same metric over training's abnormal samples. Ideally, the last one should be larger\n","\n","### Cosine similarity"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Over unseen normal samples"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:24:40.429496Z","iopub.status.busy":"2023-07-02T12:24:40.429186Z","iopub.status.idle":"2023-07-02T12:24:40.436258Z","shell.execute_reply":"2023-07-02T12:24:40.435145Z","shell.execute_reply.started":"2023-07-02T12:24:40.429469Z"},"trusted":true},"outputs":[],"source":["def analyze_similarities(df_original, df_reconstructed):\n","    similarities = []\n","    for row in tqdm(range(len(df_reconstructed))):\n","        original_row = df_original[row].reshape(1, -1)\n","        reconstructed_row = df_reconstructed[row].reshape(1, -1)\n","        similarities.append(cosine_similarity(original_row, reconstructed_row))\n","    return np.mean(similarities), np.std(similarities)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:38:40.964348Z","iopub.status.busy":"2023-07-02T12:38:40.963907Z","iopub.status.idle":"2023-07-02T12:39:55.747856Z","shell.execute_reply":"2023-07-02T12:39:55.746732Z","shell.execute_reply.started":"2023-07-02T12:38:40.964315Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6407/6407 [==============================] - 8s 1ms/step\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b0bcd4f9c6b47fa8615875bb4cb0e14","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/205022 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(0.9836996324052211, 0.014908229002202956)"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["analyze_similarities(X_val[y_val[\"is_installed\"] == 0], autoencoder.predict(X_val[y_val[\"is_installed\"] == 0]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Over unseen abnormal samples"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-07-02T12:39:55.750315Z","iopub.status.busy":"2023-07-02T12:39:55.749983Z","iopub.status.idle":"2023-07-02T12:40:10.629715Z","shell.execute_reply":"2023-07-02T12:40:10.628630Z","shell.execute_reply.started":"2023-07-02T12:39:55.750288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1249/1249 [==============================] - 1s 1ms/step\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dea79b73cdd404f89397f8ca611e9ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/39961 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(0.9853235961976019, 0.01263236184981765)"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["analyze_similarities(X_val[y_val[\"is_installed\"] == 1], autoencoder.predict(X_val[y_val[\"is_installed\"] == 1]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
